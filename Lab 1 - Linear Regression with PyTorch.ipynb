{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 - Linear Regression with PyTorch\n",
    "\n",
    "## Objective\n",
    "\n",
    "* To perform linear regression using PyTorch for understanding the link between linear models and neural networks.\n",
    "\n",
    "**Suggested reading**: \n",
    "* What is PyTorch from [PyTorch tutorial](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py)\n",
    "\n",
    "#### Assumptions: basic python programming and [Anaconda](https://anaconda.org/) installed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why\n",
    "\n",
    "[Linear regression](https://en.wikipedia.org/wiki/Linear_regression) is a fundamental problem in statistics and machine learning. Using PyTorch, a deep learing library, to do linear regression will help bridge simple linear models with complex neural networks.\n",
    "\n",
    "## 1. PyTorch Installation and Basics\n",
    "\n",
    "### Install-1: direct installation (e.g., on your own machine with full installation right)\n",
    "\n",
    "#### Install [PyTorch](https://github.com/pytorch/pytorch) via [Anaconda](https://anaconda.org/)\n",
    "`conda install -c pytorch pytorch`\n",
    "\n",
    "When you are asked whether to proceed, say `y`\n",
    "\n",
    "#### Install [torchvision](https://github.com/pytorch/vision)\n",
    "`conda install -c pytorch torchvision`\n",
    "\n",
    "When you are asked whether to proceed, say `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install-2: Set up Anaconda Python environment (e.g., on a university desktop)\n",
    "\n",
    "On a university desktop, you may not have permission to install new packages on the main environment of Anaconda. Please follow the instructions below to set up a new environment. This is also recommended if you have different python projects running that may require different environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open a command line terminal.\n",
    "\n",
    "**Create a new conda environment with Python 3.6**<br>\n",
    "`conda create -n mlai19 python=3.6 anaconda`\n",
    "\n",
    "**Activate the conda environment `mlai19`**<br>\n",
    "`activate mlai19` (Windows)<br>\n",
    "`source activate mlai19` (Mac/Linux)<br>\n",
    "You will see `(mlai19)` on the left indciating your environment\n",
    "\n",
    "**Install Pytorch and Torchvision** (non-CUDA/GPU version for simplicity)<br>\n",
    "`conda install pytorch torchvision cpuonly -c pytorch`<br>\n",
    "If you have GPU, install the GPU version with command at [here](https://pytorch.org/)\n",
    "\n",
    "**Start Jupyter notebook server**: `jupyter notebook`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor\n",
    "Optional: Go over the first two modules of [PyTorch tutorial](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py), *What is PyTorch* and *Autograd*\n",
    "\n",
    "`torch.Tensor` is \n",
    "a multidimensional array data structure (array). You may check out the full list of [tensor types](http://pytorch.org/docs/master/tensors.html) and various [tensor operations](https://pytorch.org/docs/stable/torch.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computational Graph\n",
    "A computation graph defines/visualises a sequence of operations to go from input to model output. \n",
    "\n",
    "Consider a linear regression model $\\hat y = Wx + b$, where $x$ is our input, $W$ is a weight matrix, $b$ is a bias, and $\\hat y$ is the predicted output. As a computation graph, this looks like:\n",
    "\n",
    "![Linear Regression Computation Graph](https://imgur.com/IcBhTjS.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch dynamically build the computational graph, for example\n",
    "![DynamicGraph.gif](https://raw.githubusercontent.com/pytorch/pytorch/master/docs/source/_static/img/dynamic_graph.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Linear Regression using PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start right away with implementing linear regression in PyTorch to study PyTorch concepts closely. This part follows the [PyTorch Linear regression example](https://github.com/pytorch/examples/tree/master/regression) that trains a **single fully-connected layer** to fit a 4th degree polynomial.\n",
    "\n",
    "### A synthetic linear regression problem\n",
    "\n",
    "* Generate model parameters, weight and bias. The weight vector and bias are both tensors, 1D and 0D, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "POLY_DEGREE = 4\n",
    "W_target = torch.randn(POLY_DEGREE, 1) * 5\n",
    "b_target = torch.randn(1) * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(W_target)\n",
    "print(b_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Next, define a number of functions to generate the input (variables) and output (target/response). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(x):\n",
    "    \"\"\"Builds features i.e. a matrix with columns [x, x^2, x^3, x^4].\"\"\"\n",
    "    x = x.unsqueeze(1)\n",
    "    return torch.cat([x ** i for i in range(1, POLY_DEGREE+1)], 1)\n",
    "\n",
    "def f(x):\n",
    "    \"\"\"Approximated function.\"\"\"\n",
    "    return x.mm(W_target) + b_target.item()\n",
    "\n",
    "def poly_desc(W, b):\n",
    "    \"\"\"Creates a string description of a polynomial.\"\"\"\n",
    "    result = 'y = '\n",
    "    for i, w in enumerate(W):\n",
    "        result += '{:+.2f} x^{} '.format(w, len(W) - i)\n",
    "    result += '{:+.2f}'.format(b[0])\n",
    "    return result\n",
    "\n",
    "def get_batch(batch_size=32):\n",
    "    \"\"\"Builds a batch i.e. (x, f(x)) pair.\"\"\"\n",
    "    random = torch.randn(batch_size)\n",
    "    x = make_features(random)\n",
    "    y = f(x)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Define a simple(st) neural network, which is a **single fully connected** (FC) layer. See [`torch.nn.Linear`](https://pytorch.org/docs/master/nn.html#torch.nn.Linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = torch.nn.Linear(W_target.size(0), 1)\n",
    "print(fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    This is a *network* with four input units, one output unit, with a bias term.\n",
    "    \n",
    "* Now generate the data. Let us try to get five pairs of (x,y) first to inspect.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_x, sample_y = get_batch(5)\n",
    "print(sample_x)\n",
    "print(sample_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Take a look at the FC layer weights (randomly initialised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fc.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Reset the gradients to zero, perform a forward pass to get prediction, and compute the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc.zero_grad()\n",
    "output = F.smooth_l1_loss(fc(sample_x), sample_y)\n",
    "loss = output.item()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Random did not give a good prediction. Let us do a backpropagation and update model parameters with gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.backward() \n",
    "for param in fc.parameters():  \n",
    "    param.data.add_(-0.1 * param.grad.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Check the updated weights and respective loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fc.weight)\n",
    "output = F.smooth_l1_loss(fc(sample_x), sample_y)\n",
    "loss = output.item()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * Now keep feeding more data until the loss is small enough. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import count\n",
    "for batch_idx in count(1):\n",
    "    # Get data\n",
    "    batch_x, batch_y = get_batch()\n",
    "\n",
    "    # Reset gradients\n",
    "    fc.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    output = F.smooth_l1_loss(fc(batch_x), batch_y)\n",
    "    loss = output.item()\n",
    "\n",
    "    # Backward pass\n",
    "    output.backward()\n",
    "\n",
    "    # Apply gradients\n",
    "    for param in fc.parameters():\n",
    "        param.data.add_(-0.1 * param.grad.data)\n",
    "\n",
    "    # Stop criterion\n",
    "    if loss < 1e-3:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loss: {:.6f} after {} batches'.format(loss, batch_idx))\n",
    "print('==> Learned function:\\t' + poly_desc(fc.weight.view(-1), fc.bias))\n",
    "print('==> Actual function:\\t' + poly_desc(W_target.view(-1), b_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exercises\n",
    "\n",
    "\n",
    "* Change the [loss function](https://pytorch.org/docs/stable/nn.html#loss-functions) to different choices and compare the results.\n",
    "  \n",
    "* Formulate another regression problem and solve it using `torch.nn`\n",
    "* Compare the `torch.nn` solution against the closed-form solution\n",
    "* Explore any other variations that you can think of to learn more\n",
    "\n",
    "\n",
    "# Acknowledgement\n",
    "Some part of this notebook is taken from the following sources\n",
    "\n",
    "* [PyTorch tutorial from CSE446, University of Washington](https://courses.cs.washington.edu/courses/cse446/18wi/sections/section7/446_pytorch_tutorial.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
